from __future__ import print_function

import numpy as np
import h5py
import os, sys
import pyFAI

sys.path.append(os.path.abspath("/data/id13/inhouse2/AJ/skript"))
import pythonmisc.pickle_utils as pu
from simplecalc.slicing import troi_to_slice, xy_to_troi, troi_to_xy

def integrate_data_employer(pickledargs_fname):
    '''
    gutwrenching way to (almost) completely uncouple the h5 access from the motherprocess
    Can be used to multiprocess.pool control the workers.
    '''
    fname =  __file__
    cmd = 'python {} {}'.format(fname, pickledargs_fname)

    # import inspect
    # linno = inspect.currentframe().f_lineno
    # print('DEBUG:\nin ' + __file__ + '\nline '+str(linno))
    # print(cmd)

    
    os_response = os.system(cmd)
    if os_response >1:
        raise ValueError('in {}\nos.system() has responded with errorcode {} in process {}'.format(fname, os_response, os.getpid()))
    

def integrate_data_worker(pickledargs_fname):
    '''
    interates troi into target_fname[target_group][XXX/data][target_index] from source_name[source_datasetpath][source_index][troi]
    with XXX = 'q_integration_1D','q_integration_2D' and 'tth_integration_2D'. all 3!
    these dataset have to allready exist with the right shape and dtype and no compression!
    '''
    
    unpickled_args = pu.unpickle_from_file(pickledargs_fname, verbose = False)
    # import inspect

    # linno = inspect.currentframe().f_lineno
    # print('DEBUG:\nin ' + __file__ + '\nline '+str(linno))
    # print(unpickled_args)

    target_fname = unpickled_args[0]
    target_grouppath = unpickled_args[1]
    target_index_list = unpickled_args[2]
    source_fname = unpickled_args[3]
    source_datasetpath = unpickled_args[4]
    source_index_list = unpickled_args[5]
    poni_fname = unpickled_args[6]
    npt_azim, npt_rad =  unpickled_args[7]    
    verbose = unpickled_args[8]
        
    if verbose:
        print('='*25)
        print('process {} is doing'.format(os.getpid()))
        for arg in unpickled_args:
            print(arg)
    

    with h5py.File(target_fname) as target_file:
        with h5py.File(source_fname,'r') as source_file:

            target_group = target_file[target_grouppath]
            frameshape = source_file[source_datasetpath][source_index_list[0]].shape

            mask = np.asarray(target_group['axes/mask'])
            mask_vert = np.asarray(target_group['axes/mask_vert'])
                
            ai = pyFAI.AzimuthalIntegrator()
            ai.reset()
            ai.load(poni_fname)

            ai_vert = pyFAI.AzimuthalIntegrator()
            ai_vert.reset()
            ai_vert.load(poni_fname)

            I_radial = np.zeros(shape=(len(target_index_list),npt_rad),dtype=np.float32)
            I_radial_vert = np.zeros(shape=(len(target_index_list),npt_rad),dtype=np.float32)

            for i,[target_index, source_index] in enumerate(zip(target_index_list,source_index_list)):
                raw_data = source_file[source_datasetpath][source_index]

                dummy1, data = ai.integrate1d(data=raw_data, mask=mask, npt=npt_rad , unit='q_nm^-1')
                I_radial[i] = data

                dummy1, data_vert = ai_vert.integrate1d(data=raw_data, mask=mask_vert, npt=npt_rad, unit='q_nm^-1')
                I_radial_vert[i] = data_vert
                
                if verbose:
                    print('process {} is integrating frame {}'.format(os.getpid(),target_index))

            target_group['q_radial/I'][:] = I_radial
            target_group['q_radial_vert/I'][:] = I_radial_vert
            

            # target_file.flush()
            
    if verbose:
        print('process {} is done'.format(os.getpid()))
        print('='*25)

if __name__=='__main__':
    ''' 
    This is used by the local function integrate_troi_employer(pickledargs_fname),
    DO NOT CHANGE
    '''
    if len(sys.argv)!=2:
        print('usage : python integrate_troi_worker <pickled_instruction_list_fname>')
    pickledargs_fname = sys.argv[1]
    integrate_data_worker(pickledargs_fname)
                        
